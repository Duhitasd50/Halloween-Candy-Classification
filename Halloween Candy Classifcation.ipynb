{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "candy_data = pd.read_csv(r\"C:\\Users\\Dee1\\Downloads\\the-ultimate-halloween-candy-power-ranking\\candy-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85 entries, 0 to 84\n",
      "Data columns (total 13 columns):\n",
      "competitorname      85 non-null object\n",
      "chocolate           85 non-null int64\n",
      "fruity              85 non-null int64\n",
      "caramel             85 non-null int64\n",
      "peanutyalmondy      85 non-null int64\n",
      "nougat              85 non-null int64\n",
      "crispedricewafer    85 non-null int64\n",
      "hard                85 non-null int64\n",
      "bar                 85 non-null int64\n",
      "pluribus            85 non-null int64\n",
      "sugarpercent        85 non-null float64\n",
      "pricepercent        85 non-null float64\n",
      "winpercent          85 non-null float64\n",
      "dtypes: float64(3), int64(9), object(1)\n",
      "memory usage: 8.7+ KB\n"
     ]
    }
   ],
   "source": [
    "candy_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.478647</td>\n",
       "      <td>0.468882</td>\n",
       "      <td>50.316764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.500140</td>\n",
       "      <td>0.373116</td>\n",
       "      <td>0.373116</td>\n",
       "      <td>0.276533</td>\n",
       "      <td>0.276533</td>\n",
       "      <td>0.383482</td>\n",
       "      <td>0.433861</td>\n",
       "      <td>0.502654</td>\n",
       "      <td>0.282778</td>\n",
       "      <td>0.285740</td>\n",
       "      <td>14.714357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>22.445341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>39.141056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>47.829754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732000</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>59.863998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>84.180290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chocolate     fruity    caramel  peanutyalmondy     nougat  \\\n",
       "count  85.000000  85.000000  85.000000       85.000000  85.000000   \n",
       "mean    0.435294   0.447059   0.164706        0.164706   0.082353   \n",
       "std     0.498738   0.500140   0.373116        0.373116   0.276533   \n",
       "min     0.000000   0.000000   0.000000        0.000000   0.000000   \n",
       "25%     0.000000   0.000000   0.000000        0.000000   0.000000   \n",
       "50%     0.000000   0.000000   0.000000        0.000000   0.000000   \n",
       "75%     1.000000   1.000000   0.000000        0.000000   0.000000   \n",
       "max     1.000000   1.000000   1.000000        1.000000   1.000000   \n",
       "\n",
       "       crispedricewafer       hard        bar   pluribus  sugarpercent  \\\n",
       "count         85.000000  85.000000  85.000000  85.000000     85.000000   \n",
       "mean           0.082353   0.176471   0.247059   0.517647      0.478647   \n",
       "std            0.276533   0.383482   0.433861   0.502654      0.282778   \n",
       "min            0.000000   0.000000   0.000000   0.000000      0.011000   \n",
       "25%            0.000000   0.000000   0.000000   0.000000      0.220000   \n",
       "50%            0.000000   0.000000   0.000000   1.000000      0.465000   \n",
       "75%            0.000000   0.000000   0.000000   1.000000      0.732000   \n",
       "max            1.000000   1.000000   1.000000   1.000000      0.988000   \n",
       "\n",
       "       pricepercent  winpercent  \n",
       "count     85.000000   85.000000  \n",
       "mean       0.468882   50.316764  \n",
       "std        0.285740   14.714357  \n",
       "min        0.011000   22.445341  \n",
       "25%        0.255000   39.141056  \n",
       "50%        0.465000   47.829754  \n",
       "75%        0.651000   59.863998  \n",
       "max        0.976000   84.180290  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "candy_data.drop(\"competitorname\", inplace = True, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets initialize x and y\n",
    "X = candy_data.drop(['chocolate'], axis=1)\n",
    "Y = candy_data.chocolate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape :  (11, 66)\n",
      "x_test shape :  (11, 19)\n",
      "y_train shape :  (66,)\n",
      "y_train shape :  (19,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.22, random_state=42)\n",
    "\n",
    "X_train = X_train.T\n",
    "print(\"x_train shape : \",X_train.shape)\n",
    "X_test = X_test.T\n",
    "print(\"x_test shape : \",X_test.shape)\n",
    "Y_train = Y_train.T\n",
    "print(\"y_train shape : \",Y_train.shape)\n",
    "Y_test = Y_test.T\n",
    "print(\"y_train shape : \",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters of the model\n",
    "# - Learn the parameters for the model by minimizing the cost\n",
    "# - Use the learned parameters to make predictions (on the test set)\n",
    "# - Analyse the results and conclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0, 5]) = [0.5        0.99330715]\n"
     ]
    }
   ],
   "source": [
    "# HELPER FUNCTIONS:\n",
    "# 1. SIGMOID\n",
    "# 2.INITIALIZE_WITH_ZEROS(DIM)\n",
    "# LETS BUILD OUR HELPER FUNCTIONS:\n",
    "# we need to compute sigmoid(w^T.x + b) = 1/(1+e^-(w^T.x + b))\n",
    "# by using np.exp()\n",
    "\n",
    "# activation function Sigmoid(z):\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    compute sigmoid of z\n",
    "    arguments:\n",
    "    z = scalar or numpy array of any size\n",
    "    retur:\n",
    "    s = sigmoid(z)\n",
    "    \"\"\"\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s\n",
    "print(\"sigmoid([0, 5]) = \" + str(sigmoid(np.array([0, 5]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE WITH ZEROS(DIM):\n",
    "def initialize_with_zeros(dim):\n",
    "    w = np.zeros((dim,1), dtype=int)\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward and backward propogation:(use np.dot, np.log)\n",
    "import numpy as np\n",
    "def propagate(w, b, X, Y): #fwd prop(from X to cost)\n",
    "    m = X.shape[1]\n",
    "    a = np.dot(w.T, X)\n",
    "    A = sigmoid(a + b)\n",
    "    cost_a1 = np.log(A).T\n",
    "    cost_a2 = np.log(1-A).T\n",
    "    cost_a = np.dot(Y, cost_a1) + np.dot((1-Y), cost_a2)\n",
    "    cost = -1/m * cost_a # end fwd prop\n",
    "    \n",
    "    dw = 1/m * (np.dot(X,(A, Y).T)) #BKWD PROP(TO FIND GRADS)\n",
    "    db = 1/m * (np.sum(A - Y))\n",
    "    \n",
    "    grads = {\"dw \": dw,\"db \":db}\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(w,b,X_train,Y_train, learning_rate, num_iterations):\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        # updating\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = (w - (learning_rate * dw))\n",
    "        b = (b - (learning_rate * db))\n",
    "        \n",
    "        #record costs:\n",
    "        if i % 10 == 0:\n",
    "            costs.append(cost)\n",
    "        if print_cost and i % 10 == 0:\n",
    "            print(\"cost afterration %i: %f\" %(i,cost))\n",
    "            \n",
    "        params = {\"w \": w, \"b \": b}\n",
    "    \n",
    "        grads = {\"dw \": dw, \"db \": db}\n",
    "        \n",
    "        return params, grads,costs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pervious function will output the learned w and b. now we have to predict the labels for datasetX. \n",
    "#lets implement the predict function.\n",
    "#1. calculate y_hat = a = o-(w^T * X + b)\n",
    "#convert entries into 0 or 1\n",
    "\n",
    "def predict(w,b, X):\n",
    "    m = X.shape[1]\n",
    "    y_predict = np.zeros(1,m)\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    a = np.dot(W.T, X)\n",
    "    \n",
    "    A = sigmoid(a + b)\n",
    "       \n",
    "    for i in range(A.shape[1]):\n",
    "        if (A[0,i] <= 0.5):\n",
    "            y_predict[0,i] = 0\n",
    "        else:\n",
    "            y_predict[0,1] = 1\n",
    "    return y_predict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets do the logistic regression:\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0075, num_iterations = 5):\n",
    "        w, b = initialize_with_zeros(X_train.shape[0])\n",
    "        parameters, grads, costs = update_parameters(w, b, X_train, Y_train, learning_rate = 0.0075, num_iterations = 5)\n",
    "        w = parameters[\"w\"]\n",
    "        b = parameters[\"b\"]\n",
    "        Y_prediction_test = predict(w, b, X_test)\n",
    "        \n",
    "        Y_prediction_train = predict(w, b, X_train)\n",
    "        \n",
    "        print(\"accuracy: {}\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "        print(\"accuracy: {}\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 1.0 \n",
      "train acc: 0.9090909090909091 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dee1\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train.T, Y_train.T)\n",
    "print(\"test acc: {} \".format(lr.score(X_test.T, Y_test.T)))\n",
    "print(\"train acc: {} \".format(lr.score(X_train.T, Y_train.T)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
